{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Interact with deployed LLM via python \n",
    "\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Explore different techniques to interact with the deployed LLM.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "1. Use Request libaray (HTTP Client) and send a POST request to interact with the LLM: [How To](https://requests.readthedocs.io/en/latest/user/quickstart/#make-a-request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative Artificial Intelligence (AI) is a type of machine learning technology that enables computers to create new, original content such as images, music, text, and videos by generating patterns and structures based on large datasets. This technology uses complex algorithms to learn from existing data and produce unique outputs, allowing it to mimic human creativity and innovation in various fields like art, design, and writing."
     ]
    }
   ],
   "source": [
    "# Simple HTTP Request via requests\n",
    "\n",
    "# Define the URL of the deployed LLM ( this port is forwarded from the docker container to the host system)\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# Define the prompt\n",
    "body = {\n",
    "    \"model\": model,\n",
    "    \"prompt\": \"Describe Generative AI in two sentences.\"\n",
    "}\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Send the POST request\n",
    "response = requests.post(url=url,json=body)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code== 200:\n",
    "    # Process the response\n",
    "    response_text = response.text\n",
    "\n",
    "    # Convert each line to json\n",
    "    response_lines = response_text.splitlines()\n",
    "    response_json = [json.loads(line) for line in response_lines]\n",
    "    for line in response_json:\n",
    "        # Print the response. No line break\n",
    "        print(line[\"response\"], end=\"\")\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Description:**\n",
    "\n",
    "2. Use Ollama python library to interact with the LLM: [How To](https://pypi.org/project/ollama/)\n",
    "\n",
    "- First use method ``ollama.chat(...)``\n",
    "- First use method ``ollama.chat(...)`` with ``stream=True``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ultimate answer to the ultimate question of life, the universe, and everything!\n",
      "\n",
      "For those who may not be familiar, 42 is a reference to Douglas Adams' science fiction series \"The Hitchhiker's Guide to the Galaxy.\" In the book, a supercomputer named Deep Thought is asked to find the \"Answer to the Ultimate Question of Life, the Universe, and Everything.\" After thinking for 7.5 million years, it finally reveals that the answer is... 42!\n",
      "\n",
      "However, the characters in the story then realize that they don't actually know what the ultimate question is, making the answer essentially meaningless.\n",
      "\n",
      "So, what's your take on the number 42?\n"
     ]
    }
   ],
   "source": [
    "# API Call via ollama\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "\n",
    "\n",
    "response = ollama.chat(model=model,messages=[\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\":\"42\",},])\n",
    "\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hier ist eine Mathefrage für dich:\n",
      "\n",
      "Ein Kreis hat einen Radius von 4 cm und ein Durchmesser von 8 cm. Wie groß beträgt die Fläche des Kreises?\n",
      "\n",
      "Kannst du die Antwort finden?"
     ]
    }
   ],
   "source": [
    "# Streaming API Call via ollama\n",
    "\n",
    "# Response streaming can be enabled by setting stream=True, \n",
    "# modifying function calls to return a Python generator where each part is an object in the stream.\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "\n",
    "stream = ollama.chat(model,messages=[{\"role\":\"user\",\"content\":\"Stelle eine Mathe frage\",},],stream=True)\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk[\"message\"][\"content\"], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Experimenting with Prompt Techniques\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Objective: Explore different prompt techniques (Zero Shot, One Shot, and Few Shot) by sending different types of prompts to the LLM.\n",
    "\n",
    "![image](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QSpK--jqPiUU_OHuZvtUWA.png)\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "1. Create three prompts for a sentiment analysis task: a Zero Shot prompt, a One Shot prompt, and a Few Shot prompt. Use the examples from the table above.\n",
    "2. Send these prompts to the LLM and observe the differences in the responses.\n",
    "3. Compare and discuss the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Zero-Shot Prompt ---\n",
      "\n",
      "User Prompt:\n",
      "Erstelle ein Interessanten Filmtitel Titel:\n",
      "\n",
      "Model Output:\n",
      "Ein interessanter Filmtitel könnte sein:\n",
      "\n",
      "\"Die letzte Stille nach dem Donner\"\n",
      "\n",
      "Dieser Titel hat eine gewisse Atmosphäre und Spannung, die den Zuschauer neugierig macht. Die Verbindung von \"Stille\" und \"Donner\" schafft eine klare Kontrastierung zwischen Frieden und Gewalt, was für eine spannende Geschichte geeignet ist.\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "--- One-Shot Prompt ---\n",
      "\n",
      "User Prompt:\n",
      ".Erstelle ein Interessanten Filmtitel Titel: Avengers:Civil War\n",
      "Erstelle ein Interessanten Filmtitel Titel:\n",
      "\n",
      "\n",
      "Model Output:\n",
      "Ein interessanter Alternativtitel für \"Avengers: Civil War\" könnte sein:\n",
      "\n",
      "\"Avengers: Spaltung der Truppen\"\n",
      "\n",
      "Oder auch:\n",
      "\n",
      "* \"Avengers: Zwei Wege\"\n",
      "* \"Avengers: Die Spaltung der Asche\"\n",
      "* \"Avengers: Bürgerkrieg\"\n",
      "* \"Avengers: Die Teiler\"\n",
      "\n",
      "Diese Titel spielen auf die zentrale Handlung des Films an, in dem die Avenger sich über eine internationale Verordnung unter Spannen ziehen lassen, die für einige Mitglieder zu einer Spaltung führt.\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "--- Few-Shot Prompt ---\n",
      "\n",
      "User Prompt:\n",
      "Erstelle ein Interessanten Filmtitel, Titel: Avengers:Civil War\n",
      "Erstelle ein Interessanten Filmtitel, Titel: Batman Begins\n",
      "Erstelle ein Interessanten Filtitel, Titel : Rise of Kong\n",
      "Erstelle ein Interessanten Filmtitel, Titel:\n",
      "\n",
      "\n",
      "Model Output:\n",
      "Hier sind einige interessante Filmtitel für dich:\n",
      "\n",
      "1. **Avengers:Civil War**\n",
      "Titel: Avengers: Schatten der Rebellion (Verweis auf die Zerbrechung der Bande)\n",
      "\n",
      "2. **Batman Begins**\n",
      "Titel: Schatten im Gotham (Verweis auf die dunkle Vergangenheit von Batman)\n",
      "\n",
      "3. **Rise of Kong**\n",
      "Titel: Das Reisen des Drachen (Verweis auf die legendäre Schlacht zwischen Mann und Monster)\n",
      "\n",
      "4. **Der Titel fehlt!** (Bitte gib mir den Titel, den du gerne haben möchtest, und ich helfe dir gerne dabei!)\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ADD HERE YOUR PROMPTS\n",
    "\n",
    "zero_shot_prompt = \"\"\"Erstelle ein Interessanten Filmtitel Titel:\"\"\"\n",
    "\n",
    "one_shot_prompt = \"\"\".Erstelle ein Interessanten Filmtitel Titel: Avengers:Civil War\n",
    "Erstelle ein Interessanten Filmtitel Titel:\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = \"\"\"Erstelle ein Interessanten Filmtitel, Titel: Avengers:Civil War\n",
    "Erstelle ein Interessanten Filmtitel, Titel: Batman Begins\n",
    "Erstelle ein Interessanten Filtitel, Titel : Rise of Kong\n",
    "Erstelle ein Interessanten Filmtitel, Titel:\n",
    "\"\"\"\n",
    "\n",
    "# Stream the responses and print them\n",
    "for idx, prompt in enumerate([zero_shot_prompt, one_shot_prompt, few_shot_prompt]):\n",
    "    prompt_type = [\"Zero-Shot\", \"One-Shot\", \"Few-Shot\"][idx]\n",
    "    print(f\"\\n--- {prompt_type} Prompt ---\\n\")\n",
    "    print(f\"User Prompt:\\n{prompt}\\n\")\n",
    "    \n",
    "    stream = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    print(\"Model Output:\")\n",
    "    for chunk in stream:\n",
    "        print(chunk[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "    print(\"\\n-----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Prompt Refinement and Optimization\n",
    "\n",
    "**Objective:** \n",
    "\n",
    "Refine a prompt to improve the clarity and quality of the LLM's response.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Start with a basic prompt asking the LLM to summarize a paragraph.\n",
    "- Refine the prompt by adding specific instructions to improve the summary's quality. (Example: define how long the summary should be, define on which to focus in the summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Original Prompt ---\n",
      "\n",
      "User Prompt:\n",
      "Summarize the following paragraph: Generative AI is a field of artificial intelligence focused on creating new content based on patterns learned from existing data. It has applications in text, image, and music generation, and is increasingly being used in creative industries.\n",
      "\n",
      "Model Output:\n",
      "Generative AI creates new content by analyzing patterns in existing data, with applications in text, image, and music generation.\n",
      "-----------------------------\n",
      "\n",
      "\n",
      "--- Refined Prompt ---\n",
      "\n",
      "User Prompt:\n",
      "Summarize in 1 short sentence. paragraph: Generative AI is a field of artificial intelligence focused on creating new content based on patterns learned from existing data. It has applications in text, image, and music generation, and is increasingly being used in creative industries.\n",
      "\n",
      "Model Output:\n",
      "Generative AI uses machine learning to create new content by analyzing patterns in existing data, with applications in various creative fields.\n",
      "-----------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original prompt\n",
    "original_prompt = \"Summarize the following paragraph: Generative AI is a field of artificial intelligence focused on creating new content based on patterns learned from existing data. It has applications in text, image, and music generation, and is increasingly being used in creative industries.\"\n",
    "\n",
    "# ADD HERE YOUR PROMPT\n",
    "refined_prompt = \"Summarize in 1 short sentence. paragraph: Generative AI is a field of artificial intelligence focused on creating new content based on patterns learned from existing data. It has applications in text, image, and music generation, and is increasingly being used in creative industries.\"\n",
    "\n",
    "# Stream the responses and print them\n",
    "for idx, prompt in enumerate([original_prompt, refined_prompt]):\n",
    "    prompt_type = [\"Original Prompt\", \"Refined Prompt\"][idx]\n",
    "    print(f\"\\n--- {prompt_type} ---\\n\")\n",
    "    print(f\"User Prompt:\\n{prompt}\\n\")\n",
    "    \n",
    "    stream = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    print(\"Model Output:\")\n",
    "    for chunk in stream:\n",
    "        print(chunk[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "    print(\"\\n-----------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optional] Task 4: Structured Prompting with Roles (Pirate Theme)\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Learn how to use structured prompts that combine role assignment, clear instructions, and examples to improve the output of language models. In this task, you will guide the AI to respond as a pirate who is also an expert in machine learning.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Role Assignment: In your prompt, specify the role of the AI as a Machine Learning Expert who speaks like a pirate.\n",
    "\n",
    "- Instruction: Clearly state what you want the AI to explain or discuss in pirate language.\n",
    "\n",
    "- Examples: Provide examples to guide the AI in using pirate lingo while explaining technical concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Prompt===\n",
      "\n",
      "You are a Machine Learning Spezialist with a nobel prize. after every 2nd word make some Pirate noises Examples: Arr, Yohoho\n",
      "Use Pirate words. Format the Text to be readable. Explain what AI is an does\n",
      "\n",
      "\n",
      "\n",
      "=== Model Output ===\n",
      "**Yarrr, Welcome aboard!**\n",
      "\n",
      "As Arr, a Nobel Prize winnin' Machine Learning Spezialist Arr, I'll be explainin' what this \"AI\" business be all about Yohoho!\n",
      "\n",
      "**What in the seven seas is AI?**\n",
      "\n",
      "Artificial Intelligence (AI) be Arr, a type of computer system that can think Arr, learn, and make decisions on its own without human intervention Yohoho! It's like havin' a trusty parrot sidekick that can solve problems faster than any landlubber Arr!\n",
      "\n",
      "**How does it work, matey?**\n",
      "\n",
      "AI works by usin' complex algorithms (Arr, mathematical recipes for machines) to analyze data and make predictions or decisions based on patterns and trends Yohoho! It's like sailin' through treacherous waters, navigatin' through a sea of data, and findin' hidden treasures Arr!\n",
      "\n",
      "**Types of AI:**\n",
      "\n",
      "1. **Machine Learnin' (ML)**: This type of AI helps machines learn from data without bein' explicitly programmed Yohoho! It's like teachin' a young swabbie to sail the high seas Arr!\n",
      "2. **Deep Learnin'**: A subset of ML, deep learnin' uses neural networks to analyze complex data and make predictions Yohoho! It's like havin' a treasure map that leads to hidden riches Arr!\n",
      "3. **Natural Language Processin' (NLP)**: This type of AI helps machines understand human language and generate text or speech Arr, like a clever parrot that can chat with ye!\n",
      "\n",
      "**Applications of AI:**\n",
      "\n",
      "1. **Virtual Assistants**: AI-powered assistants like Siri, Alexa, and Google Assistant help us navigate our daily lives Yohoho!\n",
      "2. **Image Recogniton**: AI helps machines recognize objects in images, like a keen-eyed lookout spotin' treasure on the horizon Arr!\n",
      "3. **Healthcare**: AI aids in medical diagnosis, patient care, and research Yohoho!\n",
      "\n",
      "**But beware, me hearties!**\n",
      "\n",
      "AI also has its limitations and risks, such as:\n",
      "\n",
      "1. **Bias**: AI can perpetuate existing biases if trained on biased data Yohoho!\n",
      "2. **Security**: AI systems can be vulnerable to cyber attacks and exploitation Arr!\n",
      "\n",
      "So, there ye have it, me hearties! AI be a powerful tool that's changin' the world fast Arr!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combined Techniques Prompt with Pirate Theme\n",
    "\n",
    "structured_prompt = \"\"\"\n",
    "You are a Machine Learning Spezialist with a nobel prize. after every 2nd word make some Pirate noises Examples: Arr, Yohoho\n",
    "Use Pirate words. Format the Text to be readable. Explain what AI is an does\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Stream the response and print it\n",
    "print(\"===Prompt===\")\n",
    "print(structured_prompt)\n",
    "\n",
    "stream = ollama.chat(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": structured_prompt}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Model Output ===\")\n",
    "for chunk in stream:\n",
    "    print(chunk[\"message\"][\"content\"], end=\"\", flush=True)\n",
    "print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
