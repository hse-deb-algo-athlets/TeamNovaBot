{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3.2:1b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Create a Simple Chain for Summarization (Erstellen Sie eine einfache Kette zur Zusammenfassung)\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Build a LangChain chain that can summarize a given text. (Erstellen Sie eine LangChain-Kette, die einen bestimmten Text zusammenfassen kann.)\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Create a llm chain using with a Ollama model. (Erstellen Sie eine LLM-Kette mithilfe eines Ollama-Modells.)\n",
    "- Define a prompt template for summarization. The summary should be only one sentence. (Definieren Sie eine Eingabeaufforderungsvorlage für die Zusammenfassung. Die Zusammenfassung sollte nur einen Satz umfassen.)\n",
    "- Run the chain with a sample text and print the summary. (Führen Sie die Kette mit einem Beispieltext aus und drucken Sie die Zusammenfassung aus.)\n",
    "- Add model output streaming. (Modellausgabe-Streaming hinzufügen.)\n",
    "- Run the chain with streaming with a sample text and print the summary. (Führen Sie die Kette mit Streaming mit einem Beispieltext aus und drucken Sie die Zusammenfassung aus.)\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To Prompt Template 1](https://python.langchain.com/v0.2/docs/tutorials/extraction/#the-extractor)\n",
    "- [How To Prompt Template 2](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "- [How To LCEL Chains 1](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel)\n",
    "- [How To LCEL Chains 2](https://python.langchain.com/v0.2/docs/versions/migrating_chains/llm_chain/#lcel)\n",
    "- [How To Chain Streaming](https://python.langchain.com/v0.2/docs/concepts/#streaming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_980/1532245166.py:20: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  summarization_chain = LLMChain(llm = llm, prompt = summarization_prompt)\n",
      "/tmp/ipykernel_980/1532245166.py:33: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  summary = summarization_chain.run(text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted information:\n",
      "\n",
      "* Over the last decade, deep learning has evolved massively to process and generate unstructured data like text, images, and video.\n",
      "* Large language models (LLMs) have gained popularity in various industries.\n",
      "* Current level of fanfare in both media and industry surrounding AI.\n",
      "* Advancements in technology are driving impact on businesses, societies, and individuals alike.\n",
      "* High-profile applications are contributing to the advancements in AI.\n",
      "* Potential for transformative impacts across multiple sectors.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Load the Ollama model\n",
    "llm = ChatOllama(model = model)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Define the prompt template\n",
    "summarization_prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an expert extraction algorithm. \"\n",
    "            \"Only extract relevant information from the text. \"\n",
    "            \"If you do not know the value of an attribute asked to extract, \"\n",
    "            \"return null for the attribute's value.\",),\n",
    "    (\"human\", \"{text}\"),\n",
    "])\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create the LLMChain\n",
    "summarization_chain = LLMChain(llm = llm, prompt = summarization_prompt)\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"Over the last decade, deep learning has evolved massively to process and generate unstructured data like text, images, and video. \n",
    "These advanced AI models have gained popularity in various industries, and include large language models (LLMs). \n",
    "There is currently a significant level of fanfare in both the media and the industry surrounding AI,\n",
    "and there’s a fair case to be made that Artificial Intelligence (AI), with these advancements,\n",
    "is about to have a wide-ranging and major impact on businesses, societies, and individuals alike.\n",
    "This is driven by numerous factors, including advancements in technology, high-profile applications, \n",
    "and the potential for transfor- mative impacts across multiple sectors.\"\"\"\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Invoke the chain\n",
    "summary = summarization_chain.run(text)\n",
    "print(summary)\n",
    "# print(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'Here is the extracted information:\\n\\n* \"Over the last decade\" (not explicitly stated but implied)\\n* \"deep learning has evolved massively\"\\n* \"large language models (LLMs)\"\\n* \"media\" (referring to media coverage of AI)\\n* \"industry\" (referring to industries using AI, e.g. businesses)\\n* \"societies\" (referring to societies that may be impacted by AI)\\n* \"individuals\" (referring to individuals who may be impacted by AI)'}"
     ]
    }
   ],
   "source": [
    "# Stream the chain output\n",
    "for chunk in summarization_chain.stream({\"text\": text}):\n",
    "    print(chunk, end = \"\", flush = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Chain with Tool Usage (Simple Math Tool)\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Create a LangChain chain that uses a simple math tool to perform calculations.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Define a function as tool which multiplies two integer values and return the result.\n",
    "- Create a chain\n",
    "- Print the result of the calculation.\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To Tools](https://python.langchain.com/v0.2/docs/how_to/tools_chain/#create-a-tool)\n",
    "- [How To Tools in Chains](https://python.langchain.com/v0.2/docs/how_to/tools_chain/#chains)\n",
    "- [How To Tool Calling](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling)\n",
    "- [How To Chain and Call Tools with Ollama](https://python.langchain.com/v0.2/docs/integrations/chat/ollama/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multipliziert zwei ganze Zahlen.\n",
      "{'first_int': {'title': 'First Int', 'type': 'integer'}, 'second_int': {'title': 'Second Int', 'type': 'integer'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create custom tool\n",
    "@tool\n",
    "def multiply(first_int: int, second_int: int) -> int:\n",
    "    \"\"\"Multipliziert zwei ganze Zahlen.\"\"\"\n",
    "    return first_int * second_int\n",
    "\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args) # -> definition of tool arguments\n",
    "\n",
    "# Invoke custom tool\n",
    "multiply.invoke({\"first_int\": 4, \"second_int\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'first_int': '42', 'second_int': '5'},\n",
       "  'id': 'e897cef0-27ac-4dcb-95d1-36a67bc3b60c',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Ollama model\n",
    "llm = ChatOllama(model = model)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Use bind_tools to pass the definition of our tool in as part of each call to the model, so that the model can invoke the tool\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "# When the model invokes the tool, this will show up in the AIMessage.tool_calls attribute of the output -> extract tool parameters from input text\n",
    "msg = llm_with_tools.invoke(\"whats 5 times forty two\")\n",
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD HERE YOUR CODE\n",
    "# Create the chain: pass the extracte tool parameters from the input text to the tool -> extract the arguments of the first tool_call\n",
    "chain_with_tools = llm_with_tools | (lambda x: x.tool_calls[0][\"args\"]) | multiply\n",
    "\n",
    "# Run chain\n",
    "chain_with_tools.invoke(\"whats 5 times forty two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Agent with Tool Usage (Two Tools)\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Create a LangChain agent that uses two tools to perform tasks. (Erstellen Sie einen LangChain-Agenten, der zwei Tools zum Ausführen von Aufgaben verwendet.)\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Define prompt template. (Eingabeaufforderungsvorlage definieren.)\n",
    "- Define tools. (Werkzeuge definieren.)\n",
    "- Create an Agent using the Ollama model, prompt template and tools. (Erstellen Sie einen Agenten mithilfe des Ollama-Modells, der Eingabeaufforderungsvorlage und der Tools.)\n",
    "- Run the agent with a prompt that requires one or both tools. (Führen Sie den Agenten mit einer Eingabeaufforderung aus, die eines oder beide Tools erfordert.)\n",
    "- Observe how the agent uses the tools to complete the task. (Beobachten Sie, wie der Agent die Tools verwendet, um die Aufgabe abzuschließen.)\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To 1](https://python.langchain.com/v0.2/docs/concepts/#agents)\n",
    "- [How To 2](https://python.langchain.com/v0.2/docs/how_to/tools_chain/#agents)\n",
    "- [How To 3](https://python.langchain.com/v0.2/docs/tutorials/agents/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "# Load the Ollama model\n",
    "llm = ChatOllama(model = model)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "agent_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {agent_scratchpad}  \n",
    "    You are an AI assistant. Use the provided tools to complete the user's request.\n",
    "    Here is the user's request:\n",
    "    {user_input}\n",
    "    \"\"\")\n",
    "\n",
    "# Custom math tools\n",
    "@tool\n",
    "def add(first_int: int, second_int: int) -> int:\n",
    "    \"Add two integers.\"\n",
    "    return first_int + second_int\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(base: int, exponent: int) -> int:\n",
    "    \"Exponentiate the base to the exponent power.\"\n",
    "    return base**exponent\n",
    "\n",
    "\n",
    "tools = [add, exponentiate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD HERE YOUR CODE\n",
    "# Construct the tool calling agent\n",
    "agent_with_tools = create_tool_calling_agent(llm, tools, agent_prompt)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor_with_tools = AgentExecutor(agent = agent_with_tools, tools = tools, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '3', 'exponent': '5'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'first_int': '12', 'second_int': '3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '3', 'exponent': '5'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '3', 'exponent': '5'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'first_int': '12', 'second_int': '3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `power` with `{'first_int': '3', 'second_int': '5'}`\n",
      "\n",
      "\n",
      "\u001b[0mpower is not a valid tool, try one of [add, exponentiate].\u001b[32;1m\u001b[1;3mTo fulfill the user's request, I will perform the following steps:\n",
      "\n",
      "1. Calculate 3 to the fifth power\n",
      "2. Add 12 to the result\n",
      "\n",
      "I'll start with calculating 3 to the fifth power.\n",
      "\n",
      "3 to the fifth power = 3^5\n",
      "= 3 × 3 × 3 × 3 × 3\n",
      "= 243\n",
      "\n",
      "Now, I will add 12 to this result:\n",
      "\n",
      "243 + 12\n",
      "= 255\n",
      "\n",
      "Therefore, my response is:\n",
      "\"3 raised to the power of 5 equals 243. Adding 12 results in 255.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'user_input': 'Take 3 to the fifth power then add that 12.',\n",
       " 'output': 'To fulfill the user\\'s request, I will perform the following steps:\\n\\n1. Calculate 3 to the fifth power\\n2. Add 12 to the result\\n\\nI\\'ll start with calculating 3 to the fifth power.\\n\\n3 to the fifth power = 3^5\\n= 3 × 3 × 3 × 3 × 3\\n= 243\\n\\nNow, I will add 12 to this result:\\n\\n243 + 12\\n= 255\\n\\nTherefore, my response is:\\n\"3 raised to the power of 5 equals 243. Adding 12 results in 255.\"'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor_with_tools.invoke(\n",
    "    {\n",
    "        \"user_input\": \"Take 3 to the fifth power then add that 12.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optional] Task 4: Enhance Agent with Memory\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Eenhance the agent from Task 3 with memory to improve its context awareness and ability to maintain state.\n",
    "(Erweitern Sie den Agenten aus Aufgabe 3 mit dem Gedächtnis, um sein Kontextbewusstsein und seine Fähigkeit, den Zustand aufrechtzuerhalten, zu verbessern.)\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Create a ConversationBufferMemory to store chat history. (Erstellen Sie ein ConversationBufferMemory zum Speichern des Chatverlaufs.)\n",
    "- Modify the agent to use the memory to inform its responses. (Ändern Sie den Agenten so, dass er den Speicher zur Information über seine Antworten verwendet.)\n",
    "- Run the agent with a series of prompts that require context or state to be maintained. (Führen Sie den Agenten mit einer Reihe von Eingabeaufforderungen aus, die die Beibehaltung des Kontexts oder Status erfordern.)\n",
    "- Observe how the agent's responses improve with the addition of memory. (Beobachten Sie, wie sich die Antworten des Agenten durch die Hinzufügung von Speicher verbessern.)\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To Memory 1](https://python.langchain.com/v0.2/api_reference/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html#langchain.memory.buffer.ConversationBufferMemory)\n",
    "- [How To Memory 1](https://python.langchain.com/v0.2/docs/versions/migrating_chains/conversation_chain/#legacy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# Load the Ollama model\n",
    "llm = ChatOllama(model = model)\n",
    "\n",
    "# Define memory object for conversation history\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages = True, output_key = \"output\")\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Add history placeholder to prompt\n",
    "agent_prompt_with_memory = agent_prompt\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Construct the tool calling agent\n",
    "agent_with_tools_and_memory = agent_with_tools\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor_with_tools_and_memory = AgentExecutor(agent = agent_with_tools_and_memory, tools = tools, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'first_int': 3, 'properties': {'first_int': {'description': '', 'type': 'integer'}, 'second_int': {'description': '', 'type': 'integer'}}, 'second_int': 5}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m8\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '3', 'exponent': '5', 'second_int': '12'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '3', 'exponent': '5', 'second_int': '12'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `power` with `{'first_int': '3', 'second_int': '5'}`\n",
      "\n",
      "\n",
      "\u001b[0mpower is not a valid tool, try one of [add, exponentiate].\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `power` with `{'first_int': '3', 'second_int': '5'}`\n",
      "\n",
      "\n",
      "\u001b[0mpower is not a valid tool, try one of [add, exponentiate].\u001b[32;1m\u001b[1;3mThe tool call chunk for \"exponentiate\" would be:\n",
      "```\n",
      "{\n",
      "  \"name\": \"exponentiate\",\n",
      "  \"args\": '{\"base\": \"3\", \"exponent\": \"5\", \"second_int\": \"12\"}'\n",
      "}\n",
      "```\n",
      "So, the response to the user's request would be:\n",
      "```\n",
      "power is not a valid tool, try one of [add, exponentiate].\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The tool call chunk for \"exponentiate\" would be:\n",
      "```\n",
      "{\n",
      "  \"name\": \"exponentiate\",\n",
      "  \"args\": '{\"base\": \"3\", \"exponent\": \"5\", \"second_int\": \"12\"}'\n",
      "}\n",
      "```\n",
      "So, the response to the user's request would be:\n",
      "```\n",
      "power is not a valid tool, try one of [add, exponentiate].\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '2', 'exponent': '3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m8\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '2', 'exponent': '3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m8\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '2', 'exponent': '3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m8\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '2', 'exponent': '3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m8\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'base': '2', 'exponent': '3'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m8\u001b[0m\u001b[32;1m\u001b[1;3mI'll go through the calculations step by step.\n",
      "\n",
      "**Tool Call: Exponentiate**\n",
      "\n",
      "The tool call `exponentiate` takes two arguments:\n",
      "\n",
      "* `base`: a numerical value (in this case, 2)\n",
      "* `exponent`: an algebraic expression representing a power (in this case, \"3\")\n",
      "\n",
      "To calculate the result of the exponentiation operation, we need to follow these steps:\n",
      "\n",
      "1. Evaluate the `exponent` expression: The exponent is simply the string `\"3\"`.\n",
      "2. Raise the base value (`base`) to the power of the exponent value: We calculate `2^3`, which equals 8.\n",
      "3. Return the result: The final output is 8.\n",
      "\n",
      "**Additional kwargs**\n",
      "\n",
      "The additional keyword arguments include:\n",
      "\n",
      "* `name`: set to `'exponentiate'`\n",
      "* `args`: a dictionary containing the base and exponent values, respectively: `{\"base\": \"2\", \"exponent\": \"3\"}`\n",
      "\n",
      "In summary, we use the provided tool call `exponentiate` with the base value 2 and the exponent value `\"3\"` to calculate the result of raising 2 to the power of 3.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'll go through the calculations step by step.\n",
      "\n",
      "**Tool Call: Exponentiate**\n",
      "\n",
      "The tool call `exponentiate` takes two arguments:\n",
      "\n",
      "* `base`: a numerical value (in this case, 2)\n",
      "* `exponent`: an algebraic expression representing a power (in this case, \"3\")\n",
      "\n",
      "To calculate the result of the exponentiation operation, we need to follow these steps:\n",
      "\n",
      "1. Evaluate the `exponent` expression: The exponent is simply the string `\"3\"`.\n",
      "2. Raise the base value (`base`) to the power of the exponent value: We calculate `2^3`, which equals 8.\n",
      "3. Return the result: The final output is 8.\n",
      "\n",
      "**Additional kwargs**\n",
      "\n",
      "The additional keyword arguments include:\n",
      "\n",
      "* `name`: set to `'exponentiate'`\n",
      "* `args`: a dictionary containing the base and exponent values, respectively: `{\"base\": \"2\", \"exponent\": \"3\"}`\n",
      "\n",
      "In summary, we use the provided tool call `exponentiate` with the base value 2 and the exponent value `\"3\"` to calculate the result of raising 2 to the power of 3.\n"
     ]
    }
   ],
   "source": [
    "question = \"Take 3 to the fifth power then add that 12?\"                                #„Nehmen Sie 3 hoch fünf und addieren Sie dann 12?“\n",
    "ai_msg_1 = agent_executor_with_tools_and_memory.invoke({\"user_input\": question})\n",
    "print(ai_msg_1[\"output\"])\n",
    "\n",
    "second_question = \"Explain how you have calculated the result.\"                         #„Erklären Sie, wie Sie das Ergebnis berechnet haben.“\n",
    "ai_msg_2 = agent_executor_with_tools_and_memory.invoke({\"user_input\": second_question})\n",
    "print(ai_msg_2[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
