{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Create a Simple Chain for Summarization\n",
    "\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Build a LangChain chain that can summarize a given text.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Create a llm chain using with a Ollama model.\n",
    "- Define a prompt template for summarization. The summary should be only one sentence.\n",
    "- Run the chain with a sample text and print the summary.\n",
    "- Add model output streaming.\n",
    "- Run the chain with streaming with a sample text and print the summary.\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To Prompt Template 1](https://python.langchain.com/v0.2/docs/tutorials/extraction/#the-extractor)\n",
    "- [How To Prompt Template 2](https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "- [How To LCEL Chains 1](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel)\n",
    "- [How To LCEL Chains 2](https://python.langchain.com/v0.2/docs/versions/migrating_chains/llm_chain/#lcel)\n",
    "- [How To Chain Streaming](https://python.langchain.com/v0.2/docs/concepts/#streaming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the Ollama model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mChatOllama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# ADD HERE YOUR CODE\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Define the prompt template\u001b[39;00m\n\u001b[0;32m      9\u001b[0m summarization_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate([\n\u001b[0;32m     10\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m),\n\u001b[0;32m     11\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{text}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     12\u001b[0m ])\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\langchain_core\\load\\serializable.py:113\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\pydantic\\v1\\main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[1;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\pydantic\\v1\\main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[1;34m(model, input_data, cls)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAssertionError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1102\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[38;5;241m=\u001b[39mROOT_KEY))\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\langchain_ollama\\chat_models.py:371\u001b[0m, in \u001b[0;36mChatOllama._set_clients\u001b[1;34m(cls, values)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set clients to use for ollama.\"\"\"\u001b[39;00m\n\u001b[0;32m    370\u001b[0m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_client\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m Client(host\u001b[38;5;241m=\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_url\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalues[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m--> 371\u001b[0m values[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_async_client\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mAsyncClient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_url\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclient_kwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\ollama\\_client.py:480\u001b[0m, in \u001b[0;36mAsyncClient.__init__\u001b[1;34m(self, host, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, host: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhttpx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAsyncClient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\ollama\\_client.py:56\u001b[0m, in \u001b[0;36mBaseClient.__init__\u001b[1;34m(self, client, host, follow_redirects, timeout, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     54\u001b[0m headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mollama-python/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplatform\u001b[38;5;241m.\u001b[39mmachine()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplatform\u001b[38;5;241m.\u001b[39msystem()\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) Python/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplatform\u001b[38;5;241m.\u001b[39mpython_version()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m  \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_parse_host\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOLLAMA_HOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m  \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m  \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py:1442\u001b[0m, in \u001b[0;36mAsyncClient.__init__\u001b[1;34m(self, auth, params, headers, cookies, verify, cert, http1, http2, proxy, proxies, mounts, timeout, follow_redirects, limits, max_redirects, event_hooks, base_url, transport, app, trust_env, default_encoding)\u001b[0m\n\u001b[0;32m   1439\u001b[0m allow_env_proxies \u001b[38;5;241m=\u001b[39m trust_env \u001b[38;5;129;01mand\u001b[39;00m app \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m transport \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1440\u001b[0m proxy_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_proxy_map(proxies \u001b[38;5;129;01mor\u001b[39;00m proxy, allow_env_proxies)\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_transport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1451\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mounts: \u001b[38;5;28mdict\u001b[39m[URLPattern, AsyncBaseTransport \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1454\u001b[0m     URLPattern(key): \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1465\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, proxy \u001b[38;5;129;01min\u001b[39;00m proxy_map\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1466\u001b[0m }\n\u001b[0;32m   1467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mounts \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\httpx\\_client.py:1490\u001b[0m, in \u001b[0;36mAsyncClient._init_transport\u001b[1;34m(self, verify, cert, http1, http2, limits, transport, app, trust_env)\u001b[0m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m app \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ASGITransport(app\u001b[38;5;241m=\u001b[39mapp)\n\u001b[1;32m-> 1490\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAsyncHTTPTransport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py:280\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.__init__\u001b[1;34m(self, verify, cert, http1, http2, limits, trust_env, proxy, uds, local_address, retries, socket_options)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    268\u001b[0m     verify: VerifyTypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    278\u001b[0m     socket_options: typing\u001b[38;5;241m.\u001b[39mIterable[SOCKET_OPTION] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 280\u001b[0m     ssl_context \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m     proxy \u001b[38;5;241m=\u001b[39m Proxy(url\u001b[38;5;241m=\u001b[39mproxy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(proxy, (\u001b[38;5;28mstr\u001b[39m, URL)) \u001b[38;5;28;01melse\u001b[39;00m proxy\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proxy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\httpx\\_config.py:55\u001b[0m, in \u001b[0;36mcreate_ssl_context\u001b[1;34m(cert, verify, trust_env, http2)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_ssl_context\u001b[39m(\n\u001b[0;32m     50\u001b[0m     cert: CertTypes \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     51\u001b[0m     verify: VerifyTypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m     trust_env: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     53\u001b[0m     http2: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     54\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLContext:\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSSLConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhttp2\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mssl_context\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\httpx\\_config.py:79\u001b[0m, in \u001b[0;36mSSLConfig.__init__\u001b[1;34m(self, cert, verify, trust_env, http2)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrust_env \u001b[38;5;241m=\u001b[39m trust_env\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp2 \u001b[38;5;241m=\u001b[39m http2\n\u001b[1;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_ssl_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\httpx\\_config.py:91\u001b[0m, in \u001b[0;36mSSLConfig.load_ssl_context\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_ssl_context verify=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cert=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m trust_env=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m http2=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp2,\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify:\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_ssl_context_verify\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_ssl_context_no_verify()\n",
      "File \u001b[1;32mc:\\Users\\sschn\\OneDrive\\Documents\\Studium\\3.Semester\\Technische Informatik\\Chatbot\\TeamNovaBot\\.venv\\Lib\\site-packages\\httpx\\_config.py:149\u001b[0m, in \u001b[0;36mSSLConfig.load_ssl_context_verify\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    147\u001b[0m     cafile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(ca_bundle_path)\n\u001b[0;32m    148\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_verify_locations cafile=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, cafile)\n\u001b[1;32m--> 149\u001b[0m     \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_verify_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcafile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcafile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ca_bundle_path\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m    151\u001b[0m     capath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(ca_bundle_path)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Load the Ollama model\n",
    "llm = ChatOllama(model=model)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Define the prompt template\n",
    "summarization_prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are an expert analyst, Summarise only important information. Use a maximum of 1 sentence with 12 Words\"),\n",
    "    (\"human\", \"{text}\"),\n",
    "])\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create the LLMChain\n",
    "summarization_chain = ChatOllama()\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"Over the last decade, deep learning has evolved massively to process and generate unstructured data like text, images, and video. \n",
    "These advanced AI models have gained popularity in various industries, and include large language models (LLMs). \n",
    "There is currently a significant level of fanfare in both the media and the industry surrounding AI,\n",
    "and there’s a fair case to be made that Artificial Intelligence (AI), with these advancements,\n",
    "is about to have a wide-ranging and major impact on businesses, societies, and individuals alike.\n",
    "This is driven by numerous factors, including advancements in technology, high-profile applications, \n",
    "and the potential for transfor- mative impacts across multiple sectors.\"\"\"\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Invoke the chain\n",
    "summary = summarization_prompt.invoke({\"text\" : text})\n",
    "print(summary.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream the chain output\n",
    "for chunk in summarization_chain.stream({\"text\": text}):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Chain with Tool Usage (Simple Math Tool)\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Create a LangChain chain that uses a simple math tool to perform calculations.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Define a function as tool which multiplies two integer values and return the result.\n",
    "- Create a chain\n",
    "- Print the result of the calculation.\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To Tools](https://python.langchain.com/v0.2/docs/how_to/tools_chain/#create-a-tool)\n",
    "- [How To Tools in Chains](https://python.langchain.com/v0.2/docs/how_to/tools_chain/#chains)\n",
    "- [How To Tool Calling](https://python.langchain.com/v0.2/docs/concepts/#functiontool-calling)\n",
    "- [How To Chain and Call Tools with Ollama](https://python.langchain.com/v0.2/docs/integrations/chat/ollama/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create custom tool\n",
    "@tool\n",
    "def multiply(...) -> ...:\n",
    "\n",
    "\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args) # -> definition of tool arguments\n",
    "\n",
    "# Invoke custom tool\n",
    "multiply.invoke({\"first_int\": 4, \"second_int\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Ollama model\n",
    "llm = ChatOllama(model=model)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Use bind_tools to pass the definition of our tool in as part of each call to the model, so that the model can invoke the tool\n",
    "llm_with_tools = ...\n",
    "\n",
    "# When the model invokes the tool, this will show up in the AIMessage.tool_calls attribute of the output -> extract tool parameters from input text\n",
    "msg = llm_with_tools.invoke(\"whats 5 times forty two\")\n",
    "print(msg.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD HERE YOUR CODE\n",
    "# Create the chain: pass the extracte tool parameters from the input text to the tool -> extract the arguments of the first tool_call\n",
    "chain_with_tools = ...\n",
    "\n",
    "# Run chain\n",
    "chain_with_tools.invoke(\"whats 5 times forty two\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Agent with Tool Usage (Two Tools)\n",
    "\n",
    "**Objective:** \n",
    "\n",
    "Create a LangChain agent that uses two tools to perform tasks.\n",
    "\n",
    "**Task Description:**\n",
    "\n",
    "- Define prompt template.\n",
    "- Define tools.\n",
    "- Create an Agent using the Ollama model, prompt template and tools.\n",
    "- Run the agent with a prompt that requires one or both tools.\n",
    "- Observe how the agent uses the tools to complete the task.\n",
    "\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To 1](https://python.langchain.com/v0.2/docs/concepts/#agents)\n",
    "- [How To 2](https://python.langchain.com/v0.2/docs/how_to/tools_chain/#agents)\n",
    "- [How To 3](https://python.langchain.com/v0.2/docs/tutorials/agents/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "# Load the Ollama model\n",
    "llm = ChatOllama(model=model)\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "agent_prompt = ...\n",
    "\n",
    "# Custom math tools\n",
    "@tool\n",
    "def add(first_int: int, second_int: int) -> int:\n",
    "    \"Add two integers.\"\n",
    "    return first_int + second_int\n",
    "\n",
    "\n",
    "@tool\n",
    "def exponentiate(base: int, exponent: int) -> int:\n",
    "    \"Exponentiate the base to the exponent power.\"\n",
    "    return base**exponent\n",
    "\n",
    "\n",
    "tools = [add, exponentiate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD HERE YOUR CODE\n",
    "# Construct the tool calling agent\n",
    "agent_with_tools = ...\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor_with_tools = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor_with_tools.invoke(\n",
    "    {\n",
    "        \"user_input\": \"Take 3 to the fifth power then add that 12.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optional] Task 4: Enhance Agent with Memory\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Eenhance the agent from Task 3 with memory to improve its context awareness and ability to maintain state.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Create a ConversationBufferMemory to store chat history.\n",
    "- Modify the agent to use the memory to inform its responses.\n",
    "- Run the agent with a series of prompts that require context or state to be maintained.\n",
    "- Observe how the agent's responses improve with the addition of memory.\n",
    "\n",
    "**Useful links:**\n",
    "\n",
    "- [How To Memory 1](https://python.langchain.com/v0.2/api_reference/langchain/memory/langchain.memory.buffer.ConversationBufferMemory.html#langchain.memory.buffer.ConversationBufferMemory)\n",
    "- [How To Memory 1](https://python.langchain.com/v0.2/docs/versions/migrating_chains/conversation_chain/#legacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# Load the Ollama model\n",
    "llm = ChatOllama(model=model)\n",
    "\n",
    "# Define memory object for conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key=\"output\")\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Add history placeholder to prompt\n",
    "agent_prompt_with_memory = ...\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Construct the tool calling agent\n",
    "agent_with_tools_and_memory = ...\n",
    "\n",
    "# ADD HERE YOUR CODE\n",
    "# Create an agent executor by passing in the agent and tools\n",
    "agent_executor_with_tools_and_memory = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Take 3 to the fifth power then add that 12?\"\n",
    "ai_msg_1 = agent_executor_with_tools_and_memory.invoke({\"user_input\": question})\n",
    "print(ai_msg_1[\"output\"])\n",
    "\n",
    "second_question = \"Explain how you have calculated the result.\"\n",
    "ai_msg_2 = agent_executor_with_tools_and_memory.invoke({\"user_input\": second_question})\n",
    "print(ai_msg_2[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
